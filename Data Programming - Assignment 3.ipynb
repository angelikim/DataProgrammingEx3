{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming - Assignment 3\n",
    "## Combining geographical numerical and textual data\n",
    "\n",
    "In this assignment you will combine weather and geonames data to find Europe's windiest cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal and issue the following commands:\n",
    "\n",
    "`$ conda install basemap\n",
    "$ pip install wget\n",
    "`\n",
    "\n",
    "Accept all to install the extra packages required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import wget\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will need to download the following 3 files. The first one is ~343MB.\n",
    "\n",
    "`http://iit.demokritos.gr/~iaklampanos/assign3_data.npz\n",
    "http://iit.demokritos.gr/~iaklampanos/lat.npy\n",
    "http://iit.demokritos.gr/~iaklampanos/lon.npy\n",
    "http://download.geonames.org/export/dump/cities5000.zip`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Write a generic function to download a file from the Web (given a URL), if it is not already present locally. The function should be parameterisable w.r.t. the local directory to be used, the default being the current working directory (`./`). Use this function to assign values to variables `data_filename`, `lat_filename` and `lon_filename`. [2 marks]**\n",
    "\n",
    "*Hint: Use the wget package.*\n",
    "\n",
    "*Hint: When developing use the smaller `lat.npy` or `lon.npy`.*\n",
    "\n",
    "*Optional: Implement a function to allow wget to display the download progress in %. Try to find your way using `help(wget)` and by looking up the source code of wget online.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def get_file_name(web_file):\n",
    "\n",
    "    if not web_file:\n",
    "        sys.exit('Please give a valid URL')\n",
    "\n",
    "    URL=web_file.split(\"/\")\n",
    "    return URL[-1]\n",
    "\n",
    "\n",
    "def file_exists(file_name,local_dir):\n",
    "    if not file_name:\n",
    "        sys.exit(\"Please give a valid file name\")\n",
    "\n",
    "    #Appending slash--Creating valid path    \n",
    "    if local_dir[-1]!=\"/\":\n",
    "        local_dir+=\"/\"\n",
    "    path=local_dir+file_name\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        return 1\n",
    "    return 0\n",
    "        \n",
    "        \n",
    "def fetch_data(web_file, local_dir='.'):\n",
    "    \"\"\"Download the `web_file`, assuming it is a web resource into the local_dir. \n",
    "    If a file with the same filename already exists in the local directory, do not \n",
    "    download it but return its path instead.\n",
    "    Arguments:\n",
    "        web_file: a web resource identifiable by a url (str)\n",
    "        local_dir: a local directory to download the web_file into (str)\n",
    "    Return: The local path to the file (str)\n",
    "    \"\"\"\n",
    "    #extracting file name\n",
    "    file_name=get_file_name(web_file)\n",
    "    \n",
    "    if not file_exists(file_name,local_dir):\n",
    "        return get_file_name(wget.download(web_file, out=local_dir))\n",
    "    \n",
    "    return file_name\n",
    "\n",
    "dest_dir=\"/home/gelou/Desktop/\"\n",
    "data_filename = fetch_data('http://iit.demokritos.gr/~iaklampanos/assign3_data_v2.npz',dest_dir) \n",
    "lat_filename =fetch_data('http://iit.demokritos.gr/~iaklampanos/lat.npy', dest_dir)\n",
    "lon_filename =fetch_data('http://iit.demokritos.gr/~iaklampanos/lon.npy',dest_dir)\n",
    "cities_filename =fetch_data('http://download.geonames.org/export/dump/cities5000.zip',dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three pieces of data you have downloaded are all numpy arrays which you can deserialise using `np.load`, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = np.load(dest_dir+data_filename)['c137']\n",
    "data = np.load(dest_dir+data_filename)['c137']\n",
    "lat = np.load(dest_dir+lat_filename)\n",
    "lon = np.load(dest_dir+lon_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geonames data (`cities5000.zip`) contains a text file (`cities5000.txt`) of tab-separated values. The description of this data is at http://download.geonames.org/export/dump/readme.txt. It lists the geographical locations and names of the cities with a population > 5000. \n",
    "\n",
    "**Unzip `cities5000.zip` to obtain `cities5000.txt`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Unziping cities5000.zip\n",
    "def extract_file(filename,local_dir):\n",
    "    \"\"\"If cities5000.txt does not exits, unzip cities5000.zip and remove it\n",
    "        *Note, assuming that the file name is the same in both compressed and uncompressed format.\n",
    "        Only file extention (zip/txt) differ.\n",
    "    \"\"\"\n",
    "    if not file_exists(filename+\".txt\",local_dir):\n",
    "\n",
    "        import zipfile\n",
    "        zip_ref = zipfile.ZipFile(local_dir + filename+\".zip\", 'r')\n",
    "        zip_ref.extractall(dest_dir)\n",
    "        zip_ref.close()\n",
    "\n",
    "        #removing zip file\n",
    "        os.remove(local_dir+filename+\".zip\")\n",
    "\n",
    "extract_file(\"cities5000\",dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) In this exercise we will need to extract the fields geonamesid, name, asciiname, \n",
    "latitude, longitude, contry code, population, elevation, dem and time zone (10 in total). Write a (*very* basic) class providing a human-readable enumeration to the fields above, corresponding to the format of the `cities5000.txt` file. [2 marks] **\n",
    "\n",
    "*Hint: e.g. for the field time zone, which is the 17th field in the file, we want to write F.TZ instead of 17. This will make our code more readable and more maintainable (e.g. in case the format changes in the future).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F(object):\n",
    "    geonamesid=0\n",
    "    name=0\n",
    "    asciiname=0\n",
    "    latityde=0\n",
    "    longitude=0\n",
    "    country_code=0\n",
    "    population=0\n",
    "    elevation=0\n",
    "    dem=0\n",
    "    time_zone=0\n",
    "    \n",
    "    def __init__(self,elements):\n",
    "        self.geonamesid=elements[0]\n",
    "        self.name=elements[1]\n",
    "        self.asciiname=elements[2]\n",
    "        self.latitude=elements[3]\n",
    "        self.longitude=elements[4]\n",
    "        self.country_code=elements[5]\n",
    "        self.population=elements[6]\n",
    "        self.elevation=elements[7]\n",
    "        self.dem=elements[8]\n",
    "        self.time_zone=elements[9]\n",
    "       \n",
    "        \n",
    "    def get_lat(self):\n",
    "        return self.latitude\n",
    "    def get_long(self):\n",
    "        return self.longitude\n",
    "    def get_population(self):\n",
    "        return self.population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3) Write a function to read cities5000.txt into a Python list, retaining the fields geonamesid, name, asciiname, latitude, longitude, contry code, population, elevation, dem and time zone. Use the class you defined above. [2 marks] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "def load_cities(filename='cities5000.txt'):\n",
    "    \"\"\"Parse cities5000.txt and return a list containing a subset of its fields.\"\"\"\n",
    "    \n",
    "    #Selecting the columns\n",
    "    coln_index=[0,1,2,4,5,8,14,15,16,17] \n",
    "    obj_list=[]\n",
    "    #Reading csv into np array\n",
    "    table = pandas.read_csv(dest_dir+\"cities5000.txt\", usecols=coln_index, delimiter=\"\\t\",header=0).as_matrix()\n",
    "\n",
    "    #Calling User Defined Constructor\n",
    "    obj_list=[F(i) for i in table]\n",
    "    return obj_list\n",
    "    \n",
    "cities = load_cities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) Write a function that given a list of cities in the format above it selects cities based on their latitude and longitude, and minimum population. We want all cities within two pairs of (lat,long), with a population >= `population`. Use your function to get all european cities (coordinates provided below) with a population >= 100000 [2 marks] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latlong_filter(lat1, lon1, lat2, lon2, population=5000, cities=cities):\n",
    "    \"\"\"Return a sublist of the geonames cities from a northwestern point (`lat1`, `lon1`) \n",
    "       to a southeastern point (`lat2`, `lon2`) and with a minimum population of `population`\n",
    "    \"\"\"\n",
    "    eur_cities=[i for i in cities if  i.get_population() >= population \\\n",
    "                and i.get_lat()>=lat2 and  i.get_lat()<=lat1\\\n",
    "                and i.get_long()>=lon1 and  i.get_long()<=lon2]\n",
    "            \n",
    "    return eur_cities\n",
    "\n",
    "LAT1 = 58.070942\n",
    "LON1 = -9.493621\n",
    "LAT2 = 34.103214\n",
    "LON2 = 29.686365\n",
    "european_cities = latlong_filter(LAT1, LON1, LAT2, LON2, 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the `data` variable... `data` has been previously used in a classification experiment and has a complicated structure. We will use only part of it. Each row has 5 data fields: \n",
    "* [0] a human-readable name\n",
    "* [1] an id\n",
    "* [2] a date & time\n",
    "* [3] a 501x501 shape\n",
    "* [4] a 3x3x64x64 shape\n",
    "\n",
    "For our exercise we will use fields 2, the datetime, and 4. 4 corresponds to weather snapshots averaged over 78hr periods (3 days and 6hrs). Datetimes and weathers repeat over 2-year periods. We need to extract the datetimes and their corresponding weathers over a 2-year period, ignoring the rest. This corresponds to 224 records (rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5) Complete the function below, which should return a *copy* of the first 224 rows of `data` retaining only datetimes and weather. [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994-01-01 00:00:00\n",
      "[ 18.7543354   19.63064957  20.34738541  20.94619751  21.36601448\n",
      "  21.56593513  21.50653839  21.15899658  20.45869637  19.41185951\n",
      "  18.16154861  16.85997009  15.59798145  14.42562008  13.38500404\n",
      "  12.47875881  11.67342567  10.9749136   10.46870518  10.22205257\n",
      "  10.19885731  10.30235481  10.4781189   10.74277687  11.12741184\n",
      "  11.63971329  12.26661205  12.96283436  13.65567398  14.30857849\n",
      "  14.94623852  15.58561325  16.21682358  16.87354851  17.63944244\n",
      "  18.5731945   19.69351006  20.99181747  22.38369942  23.74370956\n",
      "  25.05333519  26.39296722  27.75135612  28.98718452  30.05546951\n",
      "  31.08932114  32.19565201  33.30862427  34.30237198  35.13780975\n",
      "  35.86120224  36.54497528  37.26142883  38.07215118  39.01210022\n",
      "  40.07359314  41.22934341  42.45135498  43.6406517   44.56845856\n",
      "  44.97548676  44.78956985  44.26766205  43.70500946]\n"
     ]
    }
   ],
   "source": [
    "def extract_time_weather(data=data, rows=224):\n",
    "    x=data[:rows,[2,4]]\n",
    "    return x\n",
    "    \n",
    "    \n",
    "times_weathers = extract_time_weather()\n",
    "assert(times_weathers[0,1][0,0].shape == (64, 64))\n",
    "\n",
    "#debugging purposes\n",
    "print times_weathers[0,0]\n",
    "print times_weathers[0,1][0,0,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather component of our data has a shape 3, 3, 64, 64. This corresponds to 3 variables (west-east wind component, south-north wind component, geopotential height), estimated at 3 pressure levels (500, 700, 900 hPa) respectively. The values are provided on a coarse 64x64 grid covering Europe.\n",
    "\n",
    "We will use wind information and our cities to find the windiest European cities per year season. But first we need to be able to find the cell, in the 64x64 image, which contains a location given a latitude, longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6) Complete the function below to convert a latitude, longitude pair into a pair of integers corresponding to the geographical point's coordinates in the 64x64 space. [2 marks]**\n",
    "\n",
    "*Hint: `convert_to_xy(latitude, longitude) -> x(0-63), y(0, 63)`*\n",
    "\n",
    "*Hint: use the `lon` and `lat` arrays defined above. Find the indexes of the input cell that is the closest to the arguments. Use the **`haversine()`** distance function provided below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "    (https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas)\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "def convert_to_xy(latitude, longitude):\n",
    "    \"\"\"Map the coordinate provided (`latitude`, `longitude`) onto the weather 64x64 grid.\"\"\"\n",
    "\n",
    "    from numpy import inf\n",
    "    dist = inf #Really big number\n",
    "    grid=[]\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            temp_dist=haversine(latitude,longitude,lat[i][j],lon[i][j])\n",
    "            if temp_dist<dist:\n",
    "                dist=temp_dist                \n",
    "                grid=[i,j]\n",
    "    return grid\n",
    "\n",
    "coordinates=[convert_to_xy(i.get_lat(),i.get_long()) for i in european_cities]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(7) Calculate the wind magnitude and append it into our wind data array. This array must have the same shape as the u- and v-wind component arrays [2] **\n",
    "\n",
    "*Hint: The magnitudes should have a shape of 3x64x64, i.e. each wind magnitude array (64x64) should correspond to a different pressure level (3 levels in total).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 64, 64)\n",
      "[[ 10.8941412   10.79307079  10.87547874 ...,  26.67889404  26.1794281\n",
      "   25.67572021]\n",
      " [ 10.97834778  11.0189352   11.25516129 ...,  28.76575089  28.23797035\n",
      "   27.70024681]\n",
      " [ 11.37099552  11.58934021  12.0028553  ...,  30.94980049  30.41217232\n",
      "   29.86017799]\n",
      " ..., \n",
      " [ 29.55350685  30.59233665  32.49417877 ...,  10.83682156  12.54159641\n",
      "   14.30465984]\n",
      " [ 33.86526871  34.79012299  36.61966324 ...,   9.97604752  11.50609493\n",
      "   13.13854313]\n",
      " [ 38.00509644  38.82108688  40.57748795 ...,  10.32608509  11.51340008\n",
      "   12.88157082]]\n"
     ]
    }
   ],
   "source": [
    "#Info from---> https://stackoverflow.com/questions/21484558/how-to-calculate-wind-direction-from-u-and-v-wind-components-in-r\n",
    "all_weathers_mags = np.sqrt([wind[1][0]**2 + wind[1][1]**2 for wind in times_weathers])\n",
    " \n",
    "print all_weathers_mags[0].shape #random selection just to check shape\n",
    "print all_weathers_mags[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(8) Calculate the average wind magnitude per season - quarters. Remember that our overall data cover 2 years [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.533726, 21.057945, 18.778358, 20.095409]\n"
     ]
    }
   ],
   "source": [
    "magnitude_averages = []\n",
    "np.roll(all_weathers_mags, 9)\n",
    "\n",
    "#Dump info:\n",
    "#winter:Dec-Feb\n",
    "#Spring:Mar-May\n",
    "#Summer:June-Aug\n",
    "#Autumn:Sept-Nov\n",
    "\n",
    "#Every season has 3 months which evaluate to 28 elements of 78-hr elements \n",
    "#So every month has approximately 9 78-hr elements\n",
    "\n",
    "#Since December is in winter, in order for our calculations to easier, we roll the array\n",
    "#so as for December 1994 to be in the start of the arrray.\n",
    "\n",
    "#In this way we can split the table into 8 parts and calculate the \"per-season mean\"\n",
    "\n",
    "\n",
    "year=112 #78hr elements\n",
    "trimester=28 #78hr elements\n",
    "\n",
    "#can be done with list comprehension, but it'll become even more unreadable\n",
    "for i in range(4):\n",
    "    season_mean=np.mean([ np.mean(all_weathers_mags[:((i+1)*trimester)]),\\\n",
    "                         np.mean(all_weathers_mags[year:((i+1)*trimester+year)])] )\n",
    "    magnitude_averages.append(season_mean)\n",
    "\n",
    "#Default behavior of mean-->The default is to compute the mean of the flattened array.\n",
    "#https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html\n",
    "\n",
    "print magnitude_averages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(9) Using the list of `european_cities` you calculated above, find the 10 windiest cities - i.e. the cities which are located in the cell with the highest magnitude - per season. Make sure you retain their indexes in `european_citites`, or that you also store their geolocation. Take into account only the 900hPa pressure level. [2 marks]**\n",
    "\n",
    "*Hint: You may want to create a function to avoid repeating code. You will also need to use the function `convert_to_xy` you created above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_cities = None\n",
    "q2_cities = None\n",
    "q3_cities = None\n",
    "q4_cities = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10) The function below displays a 64x64 data array onto a map. Change it so that it also displays a list of points - you will use this functionality to display city locations. Use your new function to display wind magnitude average and the 10 windiest cities per season. [2 marks]**\n",
    "\n",
    "*Hint: You will need to create 4 maps, one per season.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 8), dpi= 80)\n",
    "def display_on_map(data, title=None, lat=lat, lon=lon):\n",
    "    im = plt.imread('map-pin.png')\n",
    "\n",
    "    m = Basemap(width=3800E3, height=3800E3,\n",
    "                resolution='l', projection='lcc', lat_0 = 50, \n",
    "                lon_0 = 10, lat_ts = 40, k_0=1.0)\n",
    "    m.drawcoastlines(linewidth=1.0, color='#444444')\n",
    "    m.drawcountries(linewidth=1.0, color='#444444')\n",
    "    m.drawmapboundary(linewidth=1.0, color='#000000')\n",
    "    x, y = m(lon, lat)\n",
    "    try:\n",
    "        pass\n",
    "        cs = m.contour(x, y, data, linewidths=1.0, colors='k')\n",
    "    except:\n",
    "        pass\n",
    "    pcl = m.pcolor(x, y, np.squeeze(data))\n",
    "    cbar = m.colorbar(pcl, location='bottom', pad='2%')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()    \n",
    "display_on_map(data[0,4][0,0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
